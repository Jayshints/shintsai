import streamlit as st
import pdfplumber
import mammoth
import openai
import os
import re
import json
import time

openai.api_key = "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"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
for key in ['extracted_text', 'translated_text', 'styled_text', 'toxic_clauses', 'last_file']:
    if key not in st.session_state:
        st.session_state[key] = None

def extract_text_from_file(file):
    if file.type == "application/pdf":
        with pdfplumber.open(file) as pdf:
            return "\n\n".join(page.extract_text() or "" for page in pdf.pages)
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        result = mammoth.extract_raw_text(file)
        return result.value
    return None

translation_cache = {}

def translate_text_batch(text, batch_size=5):
    paragraphs = [p.strip() for p in text.split("\n\n") if p.strip()]
    batches = [paragraphs[i:i + batch_size] for i in range(0, len(paragraphs), batch_size)]
    total_batches = len(batches)

    st.markdown(f"#### ğŸ”„ ë²ˆì—­ ì¤‘... ì´ {len(paragraphs)}ë¬¸ë‹¨ ({total_batches}ë°°ì¹˜)")
    progress_bar = st.progress(0)
    status_text = st.empty()
    all_translated = []

    for batch_idx, batch in enumerate(batches):
        batch_text = "\n\n---PARAGRAPH_SEPARATOR---\n\n".join(batch)
        status_text.markdown(f"ğŸ“˜ ë²ˆì—­ ì¤‘: ë°°ì¹˜ {batch_idx + 1}/{total_batches}")

        if batch_text in translation_cache:
            batch_results = translation_cache[batch_text].split("\n\n---PARAGRAPH_SEPARATOR---\n\n")
        else:
            for attempt in range(3):
                try:
                    response = openai.chat.completions.create(
                        model="gpt-4-turbo",
                        messages=[
                            {"role": "system", "content": (
                                "You are a legal translator. Translate the following English contract paragraphs into formal Korean. "
                                "Preserve paragraph breaks. Paragraphs are separated by '---PARAGRAPH_SEPARATOR---'."
                            )},
                            {"role": "user", "content": batch_text}
                        ],
                        temperature=0.3
                    )
                    translated_batch = response.choices[0].message.content.strip()
                    translation_cache[batch_text] = translated_batch
                    batch_results = translated_batch.split("\n\n---PARAGRAPH_SEPARATOR---\n\n")
                    break
                except Exception as e:
                    if attempt == 2:
                        batch_results = [f"ë²ˆì—­ ì˜¤ë¥˜: {e}"] * len(batch)
                    time.sleep(2)

        all_translated.extend(batch_results)
        progress_bar.progress(min((batch_idx + 1) / total_batches, 1.0))

    return "\n\n".join(all_translated)

def emphasize_titles(text):
    return re.sub(r"(ì œ\s?\d+\s?ì¡°(?:\s?[^\n]*))", r"**\1**", text)

def detect_toxic_clauses_batch(original_text, translated_text, batch_size=8):
    original_paragraphs = [p.strip() for p in original_text.split("\n\n") if p.strip()]
    translated_paragraphs = [p.strip() for p in translated_text.split("\n\n") if p.strip()]
    paired = [{"original": o, "translated": t} for o, t in zip(original_paragraphs, translated_paragraphs)]

    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()

    for i in range(0, len(paired), batch_size):
        batch = paired[i:i + batch_size]
        batch_idx = i // batch_size
        status_text.markdown(f"â˜ ï¸ ë…ì†Œì¡°í•­ ê°ì§€ ì¤‘... ë°°ì¹˜ {batch_idx + 1}/{(len(paired)-1)//batch_size + 1}")

        for attempt in range(3):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4-turbo",
                    messages=[
                        {"role": "system", "content": (
                            "You are a legal expert. For each contract paragraph pair, identify toxic clauses.\n\n"
                            "Return a JSON array in the following format:\n"
                            "[{\n"
                            "  \"title\": \"ì¡°í•­ ì œëª©\",\n"
                            "  \"original\": \"ì˜ë¬¸ ì¡°í•­\",\n"
                            "  \"translated\": \"í•œê¸€ ë²ˆì—­\",\n"
                            "  \"risk\": \"ìœ„í—˜ ìš”ì†Œ ì„¤ëª…\",\n"
                            "  \"revision_ko\": \"ìœ„í—˜ ì™„í™”ë¥¼ ìœ„í•œ ìˆ˜ì • ì œì•ˆ (í•œê¸€)\",\n"
                            "  \"revision_en\": \"ìˆ˜ì •ëœ ì˜ë¬¸ ì¡°í•­ ì œì•ˆ\"\n"
                            "}]\n\n"
                            "If no issue is found, return an empty array [].\n"
                            "âš ï¸ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ê·¸ ì™¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."
                        )},
                        {"role": "user", "content": json.dumps(batch, ensure_ascii=False)}
                    ],
                    temperature=0.3
                )
                response_text = response.choices[0].message.content.strip()
                response_text = re.sub(r'^```(json)?', '', response_text).strip('` \n')
                parsed = json.loads(response_text)
                if isinstance(parsed, list):
                    results.extend(parsed)
                break
            except Exception as e:
                if attempt == 2:
                    st.warning(f"âš ï¸ ë°°ì¹˜ {batch_idx+1} ì˜¤ë¥˜: {e}")
                time.sleep(2)

        progress_bar.progress(min((i + batch_size) / len(paired), 1.0))

    return results

# Streamlit UI
st.set_page_config(page_title="SHINTS ê³„ì•½ì„œ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ“„ SHINTS AI ë²ˆì—­ + ë…ì†Œì¡°í•­ ê°ì§€ê¸°")
st.caption("AI ê¸°ë°˜ ê³ ë„í™” ë¶„ì„ (ìœ„í—˜ ì‹ë³„ + ê°œì„ ì•ˆ ì œì‹œ)")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    batch_size = st.slider("ë²ˆì—­ ë°°ì¹˜ í¬ê¸°", 1, 10, 5)
    toxic_batch_size = st.slider("ë…ì†Œì¡°í•­ ê°ì§€ ë°°ì¹˜ í¬ê¸°", 1, 15, 8)

uploaded_file = st.file_uploader("ğŸ“¤ PDF ë˜ëŠ” Word íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "docx"])

if uploaded_file:
    file_name = uploaded_file.name
    if st.session_state.last_file != file_name:
        for key in ['extracted_text', 'translated_text', 'styled_text', 'toxic_clauses']:
            st.session_state[key] = None
        st.session_state.last_file = file_name

    start = time.time()

    if not st.session_state.extracted_text:
        with st.status("ğŸ“„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...", expanded=True) as status:
            extracted = extract_text_from_file(uploaded_file)
            if not extracted:
                st.error("âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
                st.stop()
            st.session_state.extracted_text = extracted
            status.update(label="âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ", state="complete", expanded=False)

    if not st.session_state.translated_text:
        with st.status("ğŸŒ ë²ˆì—­ ì¤‘...", expanded=True) as status:
            translated = translate_text_batch(st.session_state.extracted_text, batch_size)
            st.session_state.translated_text = translated
            st.session_state.styled_text = emphasize_titles(translated)
            status.update(label="âœ… ë²ˆì—­ ì™„ë£Œ", state="complete", expanded=False)

    tab1, tab2 = st.tabs(["ğŸ“˜ ì „ë¬¸ ë²ˆì—­", "â˜ ï¸ ë…ì†Œì¡°í•­ ê°ì§€ ë° ìˆ˜ì •ì•ˆ"])

    with tab1:
        st.markdown(f"""
            <div style='background-color:#f0f2f6; padding:20px; border-radius:10px; line-height:2; font-size:16px;'>
            {st.session_state.styled_text.replace("\n", "<br>")}
            </div>
        """, unsafe_allow_html=True)

        st.download_button(
            label="ğŸ“¥ ë²ˆì—­ë¬¸ ë‹¤ìš´ë¡œë“œ (TXT)",
            data=st.session_state.translated_text,
            file_name=f"{os.path.splitext(file_name)[0]}_translated.txt",
            mime="text/plain"
        )

    with tab2:
        if not st.session_state.toxic_clauses:
            with st.status("â˜ ï¸ ë…ì†Œì¡°í•­ ê°ì§€ ì¤‘...", expanded=True) as status:
                st.session_state.toxic_clauses = detect_toxic_clauses_batch(
                    st.session_state.extracted_text,
                    st.session_state.translated_text,
                    toxic_batch_size
                )
                status.update(label="âœ… ê°ì§€ ì™„ë£Œ", state="complete", expanded=False)

        if st.session_state.toxic_clauses:
            st.markdown(f"### âš ï¸ ì´ {len(st.session_state.toxic_clauses)}ê°œ ë…ì†Œì¡°í•­ ê°ì§€ë¨")
            for i, clause in enumerate(st.session_state.toxic_clauses, 1):
                with st.expander(f"{i}. {clause.get('title', 'ì œëª© ì—†ìŒ')}"):
                    st.markdown(f"""
                        **ğŸ”¹ ì›ë¬¸:**<br>{clause.get('original', '')}<br><br>
                        **ğŸ“˜ ë²ˆì—­:**<br>{clause.get('translated', '')}<br><br>
                        **âš ï¸ ìœ„í—˜ ìš”ì†Œ:**<br>{clause.get('risk', '')}<br><br>
                        **ğŸ›  ìœ„í—˜ ì™„í™” ì œì•ˆ (í•œê¸€):**<br>{clause.get('revision_ko', 'N/A')}<br><br>
                        **âœï¸ ìˆ˜ì •ëœ ì˜ì–´ ë¬¸ì¥:**<br>{clause.get('revision_en', 'N/A')}
                    """, unsafe_allow_html=True)
        else:
            st.info("â˜‘ï¸ ê°ì§€ëœ ë…ì†Œì¡°í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.success(f"ğŸ‰ ì „ì²´ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {time.time() - start:.1f}ì´ˆ")




